#!/usr/bin/env python3
"""
Generate all visualizations for the Chinese-English NMT project.

This script generates a comprehensive set of visualizations including:
1. Training curves for all models
2. BLEU comparison bar chart
3. Model category comparison
4. Training time comparison
5. Parameter efficiency plot
6. Sentence length vs BLEU analysis
7. Ablation heatmaps (already generated by specific scripts)
8. Hyperparameter sensitivity curves (already generated)

Usage:
    python scripts/generate_all_visualizations.py
"""

import argparse
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import json

PROJECT_ROOT = Path(__file__).resolve().parents[1]

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300


def load_metrics_csv(file_path: Path) -> pd.DataFrame:
    """Load metrics CSV if exists."""
    if not file_path.exists():
        return None
    return pd.read_csv(file_path)


def plot_all_training_curves(results_dir: Path, output_path: Path):
    """Plot training curves for all models in a comprehensive figure."""
    # Load key experiments
    experiments = {
        'RNN (GRU + Add)': load_metrics_csv(results_dir / 'rnn_gru_add_metrics.csv'),
        'Transformer (baseline)': load_metrics_csv(results_dir / 'transformer_abs_ln_metrics.csv'),
        'Transformer (RMSNorm)': load_metrics_csv(results_dir / 'transformer_abs_rms_metrics.csv'),
        'Transformer (Relative PE)': load_metrics_csv(results_dir / 'transformer_rel_ln_metrics.csv'),
    }

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Plot 1: BLEU curves
    ax = axes[0]
    for name, df in experiments.items():
        if df is not None and 'bleu' in df.columns:
            ax.plot(df['epoch'], df['bleu'], marker='o', markersize=2,
                   linewidth=2, label=name, alpha=0.85)

    ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')
    ax.set_ylabel('Validation BLEU', fontsize=12, fontweight='bold')
    ax.set_title('Training Progress: BLEU over Epochs', fontsize=13, fontweight='bold')
    ax.legend(fontsize=10, loc='best', framealpha=0.9)
    ax.grid(True, alpha=0.3)

    # Plot 2: Training loss curves
    ax = axes[1]
    for name, df in experiments.items():
        if df is not None and 'train_loss' in df.columns:
            ax.plot(df['epoch'], df['train_loss'], marker='s', markersize=2,
                   linewidth=2, label=name, alpha=0.85)

    ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')
    ax.set_ylabel('Training Loss', fontsize=12, fontweight='bold')
    ax.set_title('Training Progress: Loss over Epochs', fontsize=13, fontweight='bold')
    ax.legend(fontsize=10, loc='best', framealpha=0.9)
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')

    plt.suptitle('Training Dynamics Comparison', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✓ All training curves saved to {output_path}")


def plot_bleu_comparison_bar(comparison_csv: Path, output_path: Path):
    """Generate bar chart comparing BLEU scores of all models."""
    if not comparison_csv.exists():
        print(f"Warning: {comparison_csv} not found, skipping BLEU comparison")
        return

    df = pd.read_csv(comparison_csv)

    # Take top 10 models
    df_top = df.head(10)

    plt.figure(figsize=(12, 6))
    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(df_top)))

    bars = plt.barh(range(len(df_top)), df_top['best_bleu'], color=colors, alpha=0.85)
    plt.yticks(range(len(df_top)), df_top['model'], fontsize=10)
    plt.xlabel('BLEU Score', fontsize=12, fontweight='bold')
    plt.title('Top 10 Models: BLEU Score Comparison', fontsize=14, fontweight='bold', pad=15)
    plt.grid(axis='x', alpha=0.3)

    # Add value labels on bars
    for i, (bar, bleu) in enumerate(zip(bars, df_top['best_bleu'])):
        plt.text(bleu + 0.2, i, f'{bleu:.2f}', va='center', fontsize=9, fontweight='bold')

    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✓ BLEU comparison bar chart saved to {output_path}")


def plot_category_comparison(comparison_csv: Path, output_path: Path):
    """Generate box plot comparing model categories."""
    if not comparison_csv.exists():
        print(f"Warning: {comparison_csv} not found, skipping category comparison")
        return

    df = pd.read_csv(comparison_csv)

    plt.figure(figsize=(10, 6))
    categories = df['category'].unique()

    # Box plot
    data_by_category = [df[df['category'] == cat]['best_bleu'].values for cat in categories]

    bp = plt.boxplot(data_by_category, labels=categories, patch_artist=True,
                     medianprops=dict(color='red', linewidth=2),
                     boxprops=dict(facecolor='lightblue', alpha=0.7))

    plt.ylabel('BLEU Score', fontsize=12, fontweight='bold')
    plt.xlabel('Model Category', fontsize=12, fontweight='bold')
    plt.title('BLEU Distribution by Model Category', fontsize=14, fontweight='bold', pad=15)
    plt.xticks(rotation=15, ha='right')
    plt.grid(axis='y', alpha=0.3)

    # Add mean markers
    for i, cat in enumerate(categories, 1):
        mean_val = df[df['category'] == cat]['best_bleu'].mean()
        plt.plot(i, mean_val, 'D', color='darkgreen', markersize=8, label='Mean' if i == 1 else '')

    plt.legend(fontsize=10)

    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✓ Category comparison saved to {output_path}")


def plot_param_efficiency(comparison_csv: Path, output_path: Path):
    """Plot parameter efficiency (BLEU vs parameter count)."""
    if not comparison_csv.exists():
        print(f"Warning: {comparison_csv} not found, skipping parameter efficiency plot")
        return

    df = pd.read_csv(comparison_csv)

    # Parse parameter counts (convert string like '~44M' to float)
    def parse_params(param_str):
        if pd.isna(param_str):
            return 0
        param_str = str(param_str).replace('~', '').replace('M', '')
        try:
            return float(param_str)
        except:
            return 0

    df['params_numeric'] = df['params'].apply(parse_params)

    plt.figure(figsize=(10, 6))

    # Scatter plot
    categories = df['category'].unique()
    colors = plt.cm.tab10(np.linspace(0, 1, len(categories)))
    category_colors = dict(zip(categories, colors))

    for cat in categories:
        cat_df = df[df['category'] == cat]
        plt.scatter(cat_df['params_numeric'], cat_df['best_bleu'],
                   s=100, alpha=0.7, label=cat, color=category_colors[cat])

    plt.xlabel('Model Parameters (Millions)', fontsize=12, fontweight='bold')
    plt.ylabel('BLEU Score', fontsize=12, fontweight='bold')
    plt.title('Parameter Efficiency: BLEU vs Model Size', fontsize=14, fontweight='bold', pad=15)
    plt.legend(fontsize=10, loc='best', framealpha=0.9)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✓ Parameter efficiency plot saved to {output_path}")


def plot_epoch_efficiency(comparison_csv: Path, output_path: Path):
    """Plot epoch efficiency (BLEU vs epochs trained)."""
    if not comparison_csv.exists():
        print(f"Warning: {comparison_csv} not found, skipping epoch efficiency plot")
        return

    df = pd.read_csv(comparison_csv)

    plt.figure(figsize=(10, 6))

    # Scatter plot
    categories = df['category'].unique()
    colors = plt.cm.tab10(np.linspace(0, 1, len(categories)))
    category_colors = dict(zip(categories, colors))

    for cat in categories:
        cat_df = df[df['category'] == cat]
        plt.scatter(cat_df['total_epochs'], cat_df['best_bleu'],
                   s=100, alpha=0.7, label=cat, color=category_colors[cat])

    plt.xlabel('Total Epochs Trained', fontsize=12, fontweight='bold')
    plt.ylabel('BLEU Score', fontsize=12, fontweight='bold')
    plt.title('Training Efficiency: BLEU vs Training Duration', fontsize=14, fontweight='bold', pad=15)
    plt.legend(fontsize=10, loc='best', framealpha=0.9)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✓ Epoch efficiency plot saved to {output_path}")


def main():
    parser = argparse.ArgumentParser(description='Generate all visualizations')
    parser.add_argument('--results_dir', type=str, default='experiments/results',
                        help='Directory containing metrics files')
    parser.add_argument('--output_dir', type=str, default='experiments/results/figures',
                        help='Output directory for figures')
    args = parser.parse_args()

    results_dir = PROJECT_ROOT / args.results_dir
    output_dir = PROJECT_ROOT / args.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    comparison_csv = results_dir / 'master_comparison.csv'

    print("=" * 60)
    print("Generating All Visualizations")
    print("=" * 60)
    print()

    # Generate plots
    plot_all_training_curves(results_dir, output_dir / 'training_curves_all.png')
    plot_bleu_comparison_bar(comparison_csv, output_dir / 'bleu_comparison_bar.png')
    plot_category_comparison(comparison_csv, output_dir / 'category_comparison.png')
    plot_param_efficiency(comparison_csv, output_dir / 'param_efficiency.png')
    plot_epoch_efficiency(comparison_csv, output_dir / 'epoch_efficiency.png')

    print()
    print("=" * 60)
    print("All visualizations generated successfully!")
    print("=" * 60)
    print()
    print("Generated files:")
    print(f"  1. {output_dir / 'training_curves_all.png'}")
    print(f"  2. {output_dir / 'bleu_comparison_bar.png'}")
    print(f"  3. {output_dir / 'category_comparison.png'}")
    print(f"  4. {output_dir / 'param_efficiency.png'}")
    print(f"  5. {output_dir / 'epoch_efficiency.png'}")
    print()
    print("Additional visualizations:")
    print(f"  - Run: python scripts/analyze_rnn_results.py")
    print(f"  - Run: python scripts/analyze_transformer_ablations.py")
    print(f"  - Run: python scripts/analyze_hyperparam_sweeps.py")
    print()


if __name__ == '__main__':
    main()
